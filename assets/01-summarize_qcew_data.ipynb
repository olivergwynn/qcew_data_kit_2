{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d254590-87b0-4727-8fd7-32384c8268b9",
   "metadata": {},
   "source": [
    "# QCEW Summarization Data Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24378428-d32a-4395-a121-1dab1ed7176b",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4b852-4302-4e14-a82f-ba2485565319",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is designed to summarize Quarterly Census of Employment and Wages (QCEW) datasets, retreived from [morpc-qcew-data-kit](https://github.com/olivergwynn/qcew_data_kit/tree/main) . The dataset(s) processed by this notebook contain detailed employment statistics, as defined by the [technical documentation](https://www.bls.gov/cew/additional-resources/open-data/csv-data-slices.htm), including the number of establishments, employment levels, total quarterly wages, and more, broken down by industry and ownership sectors for each county and a whole regional summary. This script takes wide/long-form QCEW data from counties and adds regional summary data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae8849-16d3-4b02-860e-2c4ddf5353d2",
   "metadata": {},
   "source": [
    "## Process Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1b139-e5a7-4700-9e95-18d23e8cb619",
   "metadata": {},
   "source": [
    "The process carried out by this workflow can be described as follows:\n",
    "  - Wide-form standardized QCEW files are summarized to generate wide-form annual and/or quarterly tables with county and region-wide data.\n",
    "  - Newly created wide-form tables are proccessed to generate long-form counterparts.\n",
    "  - For each processed long and wide-from '.csv', a .resource.yaml file is created, following the Frictionless Data Resource specification. This file includes metadata about the CSV file, such as its name, path, format, and the schema it conforms to, as well as a hash code for integrity checking. Additionally, it contains descriptive information about the dataset and references to its source\n",
    "  - The YAML files for schemas and resource descriptors are used to make data more usable by simplifying its publication and consumption. By adhering to Frictionless standards, the script ensures that the datasets it produces are easily shareable, validatable, and integrable into a wide range of data tools and platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7452ef6-f4a7-4591-bdca-e5651a688912",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd4635-1e8d-4968-bfcc-4f06026f9150",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c369e44-61ec-44ab-8b2c-c0f99036bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import json\n",
    "import frictionless\n",
    "import requests\n",
    "import sys\n",
    "from io import StringIO\n",
    "sys.path.append(os.path.normpath(\"../../morpc-common\"))\n",
    "import morpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b2348-09f4-466f-bf5c-6a5ee11c7200",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556074e-da73-4d3d-8a09-bb792665ed16",
   "metadata": {},
   "source": [
    "#### Static parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b67b3ae-51c7-4399-9c3d-48cdc7d8d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location where output files will be saved\n",
    "OUTPUT_DIR = os.path.normpath(\"./output_data\")\n",
    "\n",
    "# Location where input files must be placed\n",
    "INPUT_DIR = os.path.normpath(\"./input_data\")\n",
    "\n",
    "# List of identifying columns for long-form tables\n",
    "id_vars = [\n",
    "    'area_fips', 'own_code', 'industry_code', 'agglvl_code', 'size_code', 'year', 'qtr', 'disclosure_code', 'lq_disclosure_code', 'oty_disclosure_code'\n",
    "]\n",
    "\n",
    "# File name for long-form quarterly table\n",
    "QCEW_QUARTERLY_LONG_OUTPUT_NAME  = \"qcew_quarterly_long_summarized.csv\" \n",
    "# File name for wide-form quarterly table\n",
    "QCEW_QUARTERLY_WIDE_OUTPUT_NAME  = \"qcew_quarterly_wide_summarized.csv\" \n",
    "\n",
    "# File name for long-form annual table\n",
    "QCEW_ANNUAL_LONG_OUTPUT_NAME  = \"qcew_annual_long_summarized.csv\" \n",
    "# File name for wide-form annual table\n",
    "QCEW_ANNUAL_WIDE_OUTPUT_NAME  = \"qcew_annual_wide_summarized.csv\" \n",
    "\n",
    "# Quarterly data paths\n",
    "QCEW_QUARTERLY_LONG_OUTPUT_PATH = os.path.join(OUTPUT_DIR, QCEW_QUARTERLY_LONG_OUTPUT_NAME)\n",
    "QCEW_QUARTERLY_WIDE_OUTPUT_PATH = os.path.join(OUTPUT_DIR, QCEW_QUARTERLY_WIDE_OUTPUT_NAME)\n",
    "\n",
    "QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE = \"qcew_quarterly_long_summarized.resource.yaml\" \n",
    "QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH = os.path.join(OUTPUT_DIR, QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE)\n",
    "QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE = \"qcew_quarterly_wide_summarized.resource.yaml\"\n",
    "QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH = os.path.join(OUTPUT_DIR, QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE)\n",
    "\n",
    "\n",
    "# Annual paths\n",
    "QCEW_ANNUAL_LONG_OUTPUT_PATH = os.path.join(OUTPUT_DIR, QCEW_ANNUAL_LONG_OUTPUT_NAME)\n",
    "QCEW_ANNUAL_WIDE_OUTPUT_PATH = os.path.join(OUTPUT_DIR, QCEW_ANNUAL_WIDE_OUTPUT_NAME)\n",
    "\n",
    "QCEW_ANNUAL_LONG_OUTPUT_RESOURCE = \"qcew_annual_long_summarized.resource.yaml\" \n",
    "QCEW_ANNUAL_LONG_OUTPUT_RESOURCE_PATH = os.path.join(OUTPUT_DIR, QCEW_ANNUAL_LONG_OUTPUT_RESOURCE)\n",
    "QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE = \"qcew_annual_wide_summarized.resource.yaml\"\n",
    "QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH = os.path.join(OUTPUT_DIR, QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE)\n",
    "\n",
    "\n",
    "# Define quarterly and annual schema directories from local copies\n",
    "QUARTERLY_TABLE_SCHEMA_FILENAME = \"morpc-qcew-quarterly.schema.yaml\"\n",
    "QUARTERLY_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, QUARTERLY_TABLE_SCHEMA_FILENAME)\n",
    "ANNUAL_TABLE_SCHEMA_FILENAME = \"morpc-qcew-annual.schema.yaml\"\n",
    "ANNUAL_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, ANNUAL_TABLE_SCHEMA_FILENAME)\n",
    "LONG_TABLE_SCHEMA_FILENAME = \"morpc-qcew-long.schema.yaml\"\n",
    "LONG_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, LONG_TABLE_SCHEMA_FILENAME)\n",
    "\n",
    "\n",
    "QCEW_ANNUAL_WIDE_INPUT_NAME  = \"qcew_annual_wide.csv\" \n",
    "\n",
    "QCEW_ANNUAL_WIDE_INPUT_PATH = os.path.join(INPUT_DIR, QCEW_ANNUAL_WIDE_INPUT_NAME)\n",
    "\n",
    "QCEW_QUARTERLY_WIDE_INPUT_NAME  = \"qcew_quarterly_wide.csv\" \n",
    "\n",
    "QCEW_QUARTERLY_WIDE_INPUT_PATH = os.path.join(INPUT_DIR, QCEW_QUARTERLY_WIDE_INPUT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78940dce-589b-43df-a432-162a4635627b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### User-set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c77c2-6a0f-494d-b661-9ecb42e5ce8a",
   "metadata": {},
   "source": [
    "### Define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c23d80-4ae6-43dd-bee0-2cc1c7570807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual schema file stored in: output_data\\morpc-qcew-annual.schema.yaml\n",
      "Quarterly schema file stored in: output_data\\morpc-qcew-quarterly.schema.yaml\n",
      "Long schema file stored in: output_data\\morpc-qcew-long.schema.yaml\n",
      "Standardized quarterly wide-form QCEW data to be summarized must be stored in: input_data\\qcew_quarterly_wide.csv\n",
      "Standardized annual wide-form QCEW data to be summarized must be stored in: input_data\\qcew_annual_wide.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Annual schema file stored in: {}\".format(ANNUAL_TABLE_SCHEMA_PATH))\n",
    "print(\"Quarterly schema file stored in: {}\".format(QUARTERLY_TABLE_SCHEMA_PATH))\n",
    "print(\"Long schema file stored in: {}\".format(LONG_TABLE_SCHEMA_PATH))\n",
    "print(\"Standardized quarterly wide-form QCEW data to be summarized must be stored in: {}\".format(QCEW_QUARTERLY_WIDE_INPUT_PATH))\n",
    "print(\"Standardized annual wide-form QCEW data to be summarized must be stored in: {}\".format(QCEW_ANNUAL_WIDE_INPUT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba4f070-ddd4-4ff0-ad3a-3ff0a85bf1a0",
   "metadata": {},
   "source": [
    "### Define outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c084e69-1d26-4f54-8651-1f27df213792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized Long quarterly QCEW data will be saved to: output_data\\qcew_quarterly_long_summarized.csv\n",
      "Summarized long quarterly QCEW data resource files will be saved to: output_data\\qcew_quarterly_long_summarized.resource.yaml\n",
      "Summarized wide quarterly QCEW data will be saved to: output_data\\qcew_quarterly_wide_summarized.csv\n",
      "Summarized wide quarterly QCEW data resource files will be saved to: output_data\\qcew_quarterly_wide_summarized.resource.yaml\n",
      "\n",
      "Summarized long annual QCEW data will be saved to: output_data\\qcew_annual_long_summarized.csv\n",
      "Summarized long annual QCEW data resource files will be saved to: output_data\\qcew_annual_long_summarized.resource.yaml\n",
      "Summarized wide annual QCEW data will be saved to: output_data\\qcew_annual_wide_summarized.csv\n",
      "Summarized wide annual QCEW data resource files will be saved to: output_data\\qcew_annual_wide_summarized.resource.yaml\n"
     ]
    }
   ],
   "source": [
    "print(\"Summarized Long quarterly QCEW data will be saved to: {}\".format(QCEW_QUARTERLY_LONG_OUTPUT_PATH))\n",
    "print(\"Summarized long quarterly QCEW data resource files will be saved to: {}\".format(QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH))\n",
    "print(\"Summarized wide quarterly QCEW data will be saved to: {}\".format(QCEW_QUARTERLY_WIDE_OUTPUT_PATH))\n",
    "print(\"Summarized wide quarterly QCEW data resource files will be saved to: {}\".format(QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "print(\"\")\n",
    "print(\"Summarized long annual QCEW data will be saved to: {}\".format(QCEW_ANNUAL_LONG_OUTPUT_PATH))\n",
    "print(\"Summarized long annual QCEW data resource files will be saved to: {}\".format(QCEW_ANNUAL_LONG_OUTPUT_RESOURCE_PATH))\n",
    "print(\"Summarized wide annual QCEW data will be saved to: {}\".format(QCEW_ANNUAL_WIDE_OUTPUT_PATH))\n",
    "print(\"Summarized wide annual QCEW data resource files will be saved to: {}\".format(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf0cd27-eee6-440f-98a2-ecbac53e365e",
   "metadata": {},
   "source": [
    "## Doing Things!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416180e-93c2-498c-98b8-0fd894d83963",
   "metadata": {},
   "source": [
    "### Wide Annual Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16452227-5217-4d5f-90f2-6d183b618b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QCEWAnnualAverage(data):\n",
    "    # Ensure that numeric columns are of numeric types before any operations\n",
    "    numeric_columns = ['annual_avg_estabs', 'annual_avg_emplvl', 'total_annual_wages',\n",
    "                       'taxable_annual_wages', 'annual_contributions']\n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Calculate additional metrics for the original data\n",
    "    data['avg_annual_pay'] = (data['total_annual_wages'] /\n",
    "                              data['annual_avg_emplvl']).replace([np.inf, -np.inf], np.nan)\n",
    "    data['annual_avg_wkly_wage'] = data['avg_annual_pay'] / 52.1775\n",
    "\n",
    "    # Create a copy of the data to perform the groupby operation and create summarized rows\n",
    "    summarized_data = data.copy()\n",
    "\n",
    "    # Perform the groupby operation to create summarized rows\n",
    "    group_columns = [\"own_code\", \"industry_code\", \"agglvl_code\", \"year\", \"qtr\"]\n",
    "    summarized_data = summarized_data.groupby(group_columns).agg({col: 'sum' for col in numeric_columns}).reset_index()\n",
    "\n",
    "    # Add the 'area_fips' as '00000' for summarized rows\n",
    "    summarized_data['area_fips'] = '00000'\n",
    "\n",
    "    # Calculate additional metrics for the summarized data\n",
    "    summarized_data['avg_annual_pay'] = (summarized_data['total_annual_wages'] /\n",
    "                                         summarized_data['annual_avg_emplvl']).replace([np.inf, -np.inf], np.nan)\n",
    "    summarized_data['annual_avg_wkly_wage'] = summarized_data['avg_annual_pay'] / 52.1775\n",
    "\n",
    "    # Append the summarized rows to the original data\n",
    "    data_grouped = pd.concat([data, summarized_data], ignore_index=True)\n",
    "\n",
    "    # Perform year-over-year change calculations on the combined dataset\n",
    "    for metric in numeric_columns + ['avg_annual_pay', 'annual_avg_wkly_wage']:\n",
    "        data_grouped[f'oty_{metric}_chg'] = data_grouped.groupby(group_columns)[metric].diff()\n",
    "        data_grouped[f'oty_{metric}_pct_chg'] = (\n",
    "            data_grouped[f'oty_{metric}_chg'] / \n",
    "            data_grouped.groupby(group_columns)[metric].shift(1)\n",
    "        ) * 100\n",
    "\n",
    "    # Replace infinite values or NaN that might have been generated due to division by zero\n",
    "    data_grouped.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data_grouped = data_grouped.infer_objects(copy=False)\n",
    "\n",
    "    # Fill NaN values that result from the diff operation on the first entry of each group with zero\n",
    "    data_grouped.fillna(0, inplace=True)\n",
    "\n",
    "    # Return the combined data with original rows and their corresponding summarized rows\n",
    "    return data_grouped\n",
    "\n",
    "def own_coder(df):\n",
    "    # Define columns to group by and columns to sum\n",
    "    group_columns = ['year', 'qtr', 'area_fips', 'industry_code', 'agglvl_code']\n",
    "    sum_columns = ['annual_avg_estabs', 'annual_avg_emplvl', 'total_annual_wages',\n",
    "                   'taxable_annual_wages', 'annual_contributions']\n",
    "\n",
    "    # Group by the specified columns and sum the other columns\n",
    "    grouped = df.groupby(group_columns)[sum_columns].sum().reset_index()\n",
    "\n",
    "    # Assign the new 'own_code'\n",
    "    grouped['own_code'] = 10\n",
    "\n",
    "    # Ensure the new aggregated rows include all necessary columns\n",
    "    # by adding missing columns with default or NaN values\n",
    "    for column in df.columns:\n",
    "        if column not in grouped:\n",
    "            grouped[column] = None  # or pd.NA for pandas' NA type\n",
    "\n",
    "    # Exclude empty or all-NA columns\n",
    "    grouped = grouped.dropna(axis=1, how='all')\n",
    "\n",
    "    # Concatenate the original DataFrame with the new aggregated DataFrame\n",
    "    result_df = pd.concat([df, grouped], ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def get_numeric_columns():\n",
    "    # Return a list of all the columns you expect to be numeric\n",
    "    return [\n",
    "        'annual_avg_estabs', 'annual_avg_emplvl', 'total_annual_wages',\n",
    "        'taxable_annual_wages', 'annual_contributions', 'avg_annual_pay', 'annual_avg_wkly_wage'\n",
    "        # Add more columns as needed\n",
    "    ]\n",
    "\n",
    "def QCEWAnnualSummary(input_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading input CSV: {e}\")\n",
    "\n",
    "    # Ensure 'qtr' and other numeric columns are processed correctly\n",
    "    columns_to_process = get_numeric_columns()\n",
    "\n",
    "    df = own_coder(df)\n",
    "    df = QCEWAnnualAverage(df)\n",
    "    \n",
    "    # Group by 'area_fips', 'year', 'qtr' and calculate proportions \n",
    "    grouped_df = df.groupby(['area_fips', 'year', 'qtr'])\n",
    "    for name, group in grouped_df:\n",
    "        divisor_row = group[(group['own_code'] == 10) & (group['agglvl_code'] == 70)]\n",
    "        if not divisor_row.empty:\n",
    "            divisor_values = divisor_row.iloc[0][columns_to_process]\n",
    "\n",
    "    df = df.replace(',', '', regex=True)\n",
    "    # Save the modified DataFrame to a CSV file\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Load the annual wide CSV\n",
    "df_annual = pd.read_csv(QCEW_ANNUAL_WIDE_INPUT_PATH)\n",
    "\n",
    "# Verify if there's data in the annual DataFrame\n",
    "if not df_annual.empty:\n",
    "    QCEWAnnualSummary(QCEW_ANNUAL_WIDE_INPUT_PATH, QCEW_ANNUAL_WIDE_OUTPUT_PATH)\n",
    "else: \n",
    "    print(\"No annual data found in: {}\".format(QCEW_ANNUAL_WIDE_INPUT_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700983c0-f632-40ea-bb44-240d3a3f1101",
   "metadata": {},
   "source": [
    "### Wide Quarterly Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935d8699-d8f2-43f1-90be-0bd11a4de60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def QCEWAnnualAverage(data):\n",
    "    # Ensure that numeric columns are of numeric types before any operations\n",
    "    numeric_columns = ['qtrly_estabs','month1_emplvl','month2_emplvl','month3_emplvl','total_qtrly_wages','taxable_qtrly_wages','qtrly_contributions']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "    # Calculate additional metrics for the original data\n",
    "    data['avg_wkly_wage'] = (data['total_qtrly_wages'] /\n",
    "                              ((data['month1_emplvl'] + data['month2_emplvl'] + data['month3_emplvl'])/3) /13    ).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Create a copy of the data to perform the groupby operation and create summarized rows\n",
    "    summarized_data = data.copy()\n",
    "\n",
    "    # Perform the groupby operation to create summarized rows\n",
    "    group_columns = [\"own_code\", \"industry_code\", \"agglvl_code\", \"year\", \"qtr\"]\n",
    "    summarized_data = summarized_data.groupby(group_columns).agg({col: 'sum' for col in numeric_columns}).reset_index()\n",
    "\n",
    "    # Calculate additional metrics for the summarized data\n",
    "    summarized_data['avg_wkly_wage'] = (summarized_data['total_qtrly_wages'] /\n",
    "                              ((summarized_data['month1_emplvl'] + summarized_data['month2_emplvl'] + summarized_data['month3_emplvl'])/3) /13    ).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    summarized_data[\"area_fips\"]='0'\n",
    "\n",
    "    # Append the summarized rows to the original data\n",
    "    data_grouped = pd.concat([data, summarized_data], ignore_index=True)\n",
    "\n",
    "    # Perform year-over-year change calculations on the combined dataset\n",
    "    for metric in numeric_columns + ['avg_wkly_wage']:\n",
    "        data_grouped[f'oty_{metric}_chg'] = data_grouped.groupby(group_columns)[metric].diff()\n",
    "        data_grouped[f'oty_{metric}_pct_chg'] = (\n",
    "            data_grouped[f'oty_{metric}_chg'] / \n",
    "            data_grouped.groupby(group_columns)[metric].shift(1)\n",
    "        ) * 100\n",
    "\n",
    "    # Replace infinite values or NaN that might have been generated due to division by zero\n",
    "    data_grouped.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data_grouped = data_grouped.infer_objects(copy=False)\n",
    "\n",
    "    # Fill NaN values that result from the diff operation on the first entry of each group with zero\n",
    "    data_grouped.fillna(0, inplace=True)\n",
    "\n",
    "    return data_grouped\n",
    "\n",
    "def own_coder(df):\n",
    "    # Define columns to group by and columns to sum\n",
    "    group_columns = ['year', 'qtr', 'area_fips', 'industry_code', 'agglvl_code']\n",
    "    sum_columns = ['qtrly_estabs', 'month1_emplvl', 'month2_emplvl',\n",
    "                   'month3_emplvl', 'total_qtrly_wages', 'taxable_qtrly_wages','qtrly_contributions','avg_wkly_wage']\n",
    "\n",
    "    # Group by the specified columns and sum the other columns\n",
    "    grouped = df.groupby(group_columns)[sum_columns].sum().reset_index()\n",
    "\n",
    "    # Assign the new 'own_code'\n",
    "    grouped['own_code'] = 10\n",
    "\n",
    "    # Ensure the new aggregated rows include all necessary columns\n",
    "    # by adding missing columns with default or NaN values\n",
    "    for column in df.columns:\n",
    "        if column not in grouped:\n",
    "            grouped[column] = None  # or pd.NA for pandas' NA type\n",
    "\n",
    "    # Exclude empty or all-NA columns\n",
    "    grouped = grouped.dropna(axis=1, how='all')\n",
    "\n",
    "    # Concatenate the original DataFrame with the new aggregated DataFrame\n",
    "    result_df = pd.concat([df, grouped], ignore_index=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def QCEWQuarterlySummary(input_csv_path, output_csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading input CSV: {e}\")\n",
    "\n",
    "    columns_to_process = ['qtrly_estabs', 'month1_emplvl', 'month2_emplvl',\n",
    "                   'month3_emplvl', 'total_qtrly_wages', 'taxable_qtrly_wages','qtrly_contributions','avg_wkly_wage']\n",
    "\n",
    "    df = own_coder(df)\n",
    "    df = QCEWAnnualAverage(df)\n",
    "    \n",
    "    # Group by 'area_fips', 'year', 'qtr' and calculate proportions \n",
    "    grouped_df = df.groupby(['area_fips', 'year', 'qtr'])\n",
    "    for name, group in grouped_df:\n",
    "        divisor_row = group[(group['own_code'] == 10) & (group['agglvl_code'] == 70)]\n",
    "        if not divisor_row.empty:\n",
    "            divisor_values = divisor_row.iloc[0][columns_to_process]\n",
    "\n",
    "    df = df.replace(',', '', regex=True)\n",
    "    # Save the modified DataFrame to a CSV file\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Load the quarterly wide CSV\n",
    "df_quarterly = pd.read_csv(QCEW_QUARTERLY_WIDE_INPUT_PATH)\n",
    "\n",
    "# Verify if there's data in the quarterly DataFrame\n",
    "if not df_quarterly.empty:\n",
    "    QCEWQuarterlySummary(QCEW_QUARTERLY_WIDE_INPUT_PATH, QCEW_QUARTERLY_WIDE_OUTPUT_PATH)\n",
    "else: \n",
    "    print(\"No quarterly data found in: {}\".format(QCEW_QUARTERLY_WIDE_INPUT_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee80b3-d283-48b2-a490-c4f13ddb093e",
   "metadata": {},
   "source": [
    "### Creating long-form annual table, if wide-form annual data exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ec05c-a52e-48b7-b50f-5e30f8dfc014",
   "metadata": {},
   "source": [
    "Melt the summarized wide-form annual data into a long-form table where each row corresponds to a single variable for a given county, year, establishment ownership, establishment size, industry, aggregation code, and disclosure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d483115-0635-43a0-a070-2f28e8922fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "annualDtypes = {\n",
    "    'disclosure_code': 'str',\n",
    "    'industry_code': 'str',\n",
    "    'lq_disclosure_code': 'str',\n",
    "    'oty_disclosure_code': 'str'\n",
    "}\n",
    "\n",
    "# Load the annual wide CSV\n",
    "df_annual = pd.read_csv(QCEW_ANNUAL_WIDE_OUTPUT_PATH, dtype=annualDtypes)\n",
    "\n",
    "# Verify if there's data in the annual DataFrame\n",
    "if not df_annual.empty:\n",
    "    value_vars_annual = df_annual.columns.difference(id_vars)\n",
    "    df_annual_long = pd.melt(df_annual, id_vars=id_vars, value_vars=value_vars_annual, \n",
    "                             var_name='variable', value_name='value')\n",
    "    df_annual_long.to_csv(QCEW_ANNUAL_LONG_OUTPUT_PATH, index=False)\n",
    "    (f\"Annual QCEW data have been saved as long into: {QCEW_ANNUAL_LONG_OUTPUT_PATH}\")\n",
    "else: \n",
    "    print(\"No annual data to melt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65b062-6c6a-44d1-9af7-35802fbce3c6",
   "metadata": {},
   "source": [
    "### Creating long-form quarterly table, if wide-form quarterly data exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306b419-9e63-4f1c-b7ca-03ad2e6f0c2d",
   "metadata": {},
   "source": [
    "Melt the summarized wide-form quarterly data into a long-form table where each row corresponds to a single variable for a given county, year, quarter, establishment ownership, establishment size, industry, aggregation code, and disclosure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c4f4804-eaa9-43f2-8f7f-7b57b24e33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterlyDtypes = {\n",
    "    'disclosure_code': 'str',\n",
    "    'industry_code': 'str',\n",
    "    'lq_disclosure_code': 'str',\n",
    "    'oty_disclosure_code': 'str'\n",
    "    #'lq_avg_wkly_wage': 'float64',\n",
    "}\n",
    "\n",
    "# Load the annual wide CSV\n",
    "df_annual = pd.read_csv(QCEW_QUARTERLY_WIDE_OUTPUT_PATH, dtype=quarterlyDtypes)\n",
    "\n",
    "# Verify if there's data in the annual DataFrame\n",
    "if not df_annual.empty:\n",
    "    value_vars_quarterly = df_annual.columns.difference(id_vars)\n",
    "    df_quarterly_long = pd.melt(df_annual, id_vars=id_vars, value_vars=value_vars_quarterly, \n",
    "                             var_name='variable', value_name='value')\n",
    "    df_quarterly_long.to_csv(QCEW_QUARTERLY_LONG_OUTPUT_PATH, index=False)\n",
    "    (f\"Quarterly QCEW data have been saved as long into: {QCEW_QUARTERLY_LONG_OUTPUT_PATH}\")\n",
    "else: \n",
    "    print(\"No annual data to melt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947d0bd-5163-40d6-a0ab-6f0821b25c93",
   "metadata": {},
   "source": [
    "## Create and validate resource file for annual wide-form table, if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f839f3-ba40-4be0-b0f7-e3358e237b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing resource file to output_data\\qcew_annual_wide_summarized.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_wide_annual = pd.read_csv(QCEW_ANNUAL_WIDE_OUTPUT_PATH, dtype=annualDtypes)\n",
    "\n",
    "# Finding the maximum and minimum values in the 'year' column\n",
    "max_year = df_wide_annual['year'].max()\n",
    "min_year = df_wide_annual['year'].min()\n",
    "\n",
    "# Update title and description with the county name\n",
    "title = f\"Compiled QCEW County Data, Annual, {min_year}-{max_year} (wide form)\"\n",
    "description = f\"Employment and wage data for counties in MOPRC region, derived from the U.S. Bureau of Labor Statistics.\"\n",
    "\n",
    "# Resource creation for WIDE ANNUAL\n",
    "if not df_wide_annual.empty:\n",
    "    acsResource = {\n",
    "        \"name\": \"qcew_annual_wide\",\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"path\": QCEW_ANNUAL_WIDE_OUTPUT_NAME,\n",
    "        \"format\": \"csv\",\n",
    "        \"mediatype\": \"text/csv\",\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"bytes\": os.path.getsize(QCEW_ANNUAL_WIDE_OUTPUT_PATH),\n",
    "        \"hash\": morpc.md5(QCEW_ANNUAL_WIDE_OUTPUT_PATH),\n",
    "        \"schema\": ANNUAL_TABLE_SCHEMA_FILENAME,\n",
    "        \"profile\":'tabular-data-resource'\n",
    "    }\n",
    "    \n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(os.path.dirname(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    dummy = resource.to_yaml(os.path.basename(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8783555-eeb2-499a-8f75-7a2c89f3da64",
   "metadata": {},
   "source": [
    "## Create and validate resource file for quarterly wide-form table, if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a8e069-50dc-43e9-82a1-39276c5239df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing resource file to output_data\\qcew_quarterly_wide_summarized.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_wide_quarterly = pd.read_csv(QCEW_QUARTERLY_WIDE_OUTPUT_PATH, dtype=quarterlyDtypes)\n",
    "\n",
    "# Finding the maximum and minimum values in the 'year' column\n",
    "max_year = df_wide_annual['year'].max()\n",
    "min_year = df_wide_annual['year'].min()\n",
    "\n",
    "# Update title and description with the county name\n",
    "title = f\"Compiled QCEW County Data, Quarterly, {min_year}-{max_year} (wide form)\"\n",
    "description = f\"Employment and wage data for counties in MOPRC region, derived from the U.S. Bureau of Labor Statistics.\"\n",
    "\n",
    "# Resource creation for WIDE QUARTERLY\n",
    "if not df_wide_quarterly.empty:\n",
    "    acsResource ={\n",
    "    \"name\": \"qcew_quarterly_wide\",\n",
    "    \"title\": title,\n",
    "    \"description\": description,\n",
    "    \"path\": QCEW_QUARTERLY_WIDE_OUTPUT_NAME,\n",
    "    \"format\": \"csv\",\n",
    "    \"mediatype\": \"text/csv\",\n",
    "    \"encoding\": \"utf-8\",\n",
    "    \"bytes\": os.path.getsize(QCEW_QUARTERLY_WIDE_OUTPUT_PATH),\n",
    "    \"hash\": morpc.md5(QCEW_QUARTERLY_WIDE_OUTPUT_PATH),\n",
    "    \"schema\": QUARTERLY_TABLE_SCHEMA_FILENAME,\n",
    "    \"profile\":'tabular-data-resource'\n",
    "    }\n",
    "    \n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(os.path.dirname(QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    dummy = resource.to_yaml(os.path.basename(QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(QCEW_QUARTERLY_WIDE_OUTPUT_RESOURCE_PATH)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70716a2d-d9f2-4e65-8787-139633209a27",
   "metadata": {},
   "source": [
    "## Create and validate resource file for annual long-form table, if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21894212-020c-461f-82de-96f9d9a98cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing resource file to output_data\\qcew_annual_long_summarized.resource.yaml\n",
      "Validating resource on disk (including data and schema). This may take some time.\n",
      "Resource is valid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_wide_annual = pd.read_csv(QCEW_ANNUAL_LONG_OUTPUT_PATH, dtype=annualDtypes)\n",
    "\n",
    "# Finding the maximum and minimum values in the 'year' column\n",
    "max_year = df_wide_annual['year'].max()\n",
    "min_year = df_wide_annual['year'].min()\n",
    "\n",
    "# Update title and description with the county name\n",
    "title = f\"Compiled QCEW County Data, Annual, {min_year}-{max_year} (long form)\"\n",
    "description = f\"Employment and wage data for counties in MOPRC region, derived from the U.S. Bureau of Labor Statistics.\"\n",
    "\n",
    "# Resource creation for LONG ANNUAL\n",
    "if not df_wide_annual.empty:\n",
    "    acsResource = {\n",
    "        \"name\": \"qcew_annual_long\",\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"path\": QCEW_ANNUAL_LONG_OUTPUT_NAME,\n",
    "        \"format\": \"csv\",\n",
    "        \"mediatype\": \"text/csv\",\n",
    "        \"encoding\": \"utf-8\",\n",
    "        \"bytes\": os.path.getsize(QCEW_ANNUAL_LONG_OUTPUT_PATH),\n",
    "        \"hash\": morpc.md5(QCEW_ANNUAL_LONG_OUTPUT_PATH),\n",
    "        \"schema\": LONG_TABLE_SCHEMA_FILENAME,\n",
    "        \"profile\":'tabular-data-resource'\n",
    "    }\n",
    "    \n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(QCEW_ANNUAL_LONG_OUTPUT_RESOURCE_PATH))\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(os.path.dirname(QCEW_ANNUAL_WIDE_OUTPUT_RESOURCE_PATH))\n",
    "    dummy = resource.to_yaml(os.path.basename(QCEW_ANNUAL_LONG_OUTPUT_RESOURCE_PATH))\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(QCEW_ANNUAL_LONG_OUTPUT_RESOURCE_PATH)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e789c2e-d489-4345-b128-6a72ebab83c6",
   "metadata": {},
   "source": [
    "## Create and validate resource file for quarterly long-form table, if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9119d-6bf1-4e99-815e-bad1feef7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_annual = pd.read_csv(QCEW_QUARTERLY_LONG_OUTPUT_PATH, dtype=annualDtypes)\n",
    "\n",
    "# Finding the maximum and minimum values in the 'year' column\n",
    "max_year = df_wide_annual['year'].max()\n",
    "min_year = df_wide_annual['year'].min()\n",
    "\n",
    "# Update title and description with the county name\n",
    "title = f\"Compiled QCEW County Data, Quarterly, {min_year}-{max_year} (long form)\"\n",
    "description = f\"Employment and wage data for counties in MOPRC region, derived from the U.S. Bureau of Labor Statistics.\"\n",
    "\n",
    "# Resource creation for WIDE ANNUAL\n",
    "if not df_wide_annual.empty:\n",
    "    \n",
    "    acsResource = {\n",
    "      \"name\": \"qcew_quarterly_long\",\n",
    "      \"title\": title,\n",
    "      \"description\": description,\n",
    "      \"path\": QCEW_QUARTERLY_LONG_OUTPUT_NAME,\n",
    "      \"format\": \"csv\",\n",
    "      \"mediatype\": \"text/csv\",\n",
    "      \"encoding\": \"utf-8\",\n",
    "      \"bytes\": os.path.getsize(QCEW_QUARTERLY_LONG_OUTPUT_PATH),\n",
    "      \"hash\": morpc.md5(QCEW_QUARTERLY_LONG_OUTPUT_PATH),\n",
    "      \"schema\": LONG_TABLE_SCHEMA_FILENAME,\n",
    "      \"profile\":'tabular-data-resource'\n",
    "    }\n",
    "    \n",
    "    # Create the resource object\n",
    "    resource = frictionless.Resource(acsResource)\n",
    "\n",
    "    print(\"Writing resource file to {}\".format(QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH))\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(os.path.dirname(QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH))\n",
    "    dummy = resource.to_yaml(os.path.basename(QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH))\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    print(\"Validating resource on disk (including data and schema). This may take some time.\")\n",
    "    resourceOnDisk = frictionless.Resource(QCEW_QUARTERLY_LONG_OUTPUT_RESOURCE_PATH)\n",
    "    results = resourceOnDisk.validate()\n",
    "    if(results.valid):\n",
    "        print(\"Resource is valid\\n\")\n",
    "    else:\n",
    "        print(\"ERROR: Resource is NOT valid. Errors follow.\\n\")\n",
    "        print(results)\n",
    "        raise RuntimeError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
